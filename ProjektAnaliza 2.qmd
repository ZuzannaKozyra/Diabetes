---
title: "Projekt z zakresu analizy danych"
author: "Zuzanna Kozyra, Michał Łysakowski"
format: 
  html:
    warning: false
    message: false
    echo: false
    self-contained: true
    toc: true
    toc-location: left
    toc-title: Spis treści
editor: visual
editor_options: 
  chunk_output_type: outline
bibliography: references.bib
---

# Cel Projektu

Badanie wpływu różnych czynników na zachorowania na cukrzyce. Zbiór danych pochodzi z instytutu ['National Institute of Diabetes and Digestive and Kidney Diseases'](https://www.niddk.nih.gov/ "strona instytutu"). W próbie wszystkie pacjentki to kobiety pochodzące z Indii, w wieku 21 lat lub starsze.

```{r warning=FALSE, message=FALSE}
library(knitr)
library(tidyverse)
library(Hotelling)
library(rstatix)
library(dplyr)
library(DT)
library(ggpubr)
library(ggcorrplot)
library(vip)
library(gridExtra)
library(caret)
library(readr)
library(forcats)
library(rstatix)
library(tidymodels)
library(MASS)
library(Metrics)
library(plotly)
library(rpart.plot)
library(randomForest)
library(caret)
```

# Opis zbioru danych

## Wczytanie danych

```{r}

dane <- read.csv('diabetes.csv')
dane <- dane %>% 
  add_column (Id = 1: nrow(dane), .before = 1)
datatable(dane[,-1])
```

## Opis zmiennych

Zmienne podane są w zbiorze `diabetes` w języku angielskim, poniżej znajduje się tabela opisująca każdą zmienną.

```{r}
#| tbl-cap: "Opis zmiennych"
#| label: tbl-opis


library(knitr)

opis <-  data.frame(matrix(c('Id', 'Numer wiersza/obserwacji',
                                'Pregnacies','Ilość przebytych ciąż',

                                'Glucose', 'Plazmowe stężenie glukozy po upływie 2 godzin w teście tolerancji glukozy doustnej',

                                'BloodPressure', 'Rozkurczowe ciśnienie krwi',

                                'SkinThickness', 'Grubość fałdu skórnego tricepsa (mm)',

                                'Insulin', 'Poziom insuliny',

                                'BMI', 'Body Mass Index, wskaźnik masy ciała (waga w kg/(wzrost w m)^2)',

                                'DiabetesPedigreeFunction', 'Funkcja obliczająca prawdopodobieństwo wystąpienia cukrzycy biorąca pod uwagę wiek oraz historie chorób w rodzinie pacjenta',
                             'Age', 'Wiek (w latach)',
                             'Outcome', 'Wynik, 1 gdy cukrzyca wystąpiła, 0 gdy cukrzyca nie wystąpiła'),ncol = 2, byrow = T))

colnames(opis) <- c("Oryginalna nazwa zmiennej", "Wyjaśnienie")

kable(opis)
```

# Sprawdzanie poprawności zbioru danych

## Występowanie braków danych

```{r}
is.na(dane) %>%
  sum() %>%
  data.frame("Brakujące_wartości" = .) %>%
  kable()
```

Brak braków danych.

## Występowanie duplikatów

```{r include=FALSE}
duplikaty <- unique(dane)
length(dane$Pregnancies) == length(duplikaty$Pregnancies)
```

Brak duplikatów danych (ilość unikalnych wartości jest taka sama jak w pierwotnej tabeli).

## Poprawność zmiennych

```{r}
#| tbl-cap: "Podstawowe statystyki"
#| label: tbl-stat1

kable(summary(dane[,-c(1,10)]))
```

Patrząc na statystyki możemy zauważyć już pewne nieścisłości, które z medycznego punktu widzenia nie mogą zachodzić u człowieka.

1.  `Pregnancies` = 17

    ```{r}
    kable(dane[dane$Pregnancies == 17,])
    ```

    Według tej obserwacji (numer 160) kobieta w wieku 47 lat przebyła 17 ciąż, więc zostaje ona usunięta ze zbioru.

    ```{r}
    dane <- dane[-160,]
    ```

2.  `Glucose` = 0

    ```{r}
    id_g <- dane %>%
      filter(Glucose == 0)

    dane <- dane %>%
      filter(!Id %in% id_g$Id)
    ```

    Na podstawie: @jeznach-steinhagen_zywienie_2020

3.  `BloodPressure` = 0

    Na podstawie: @jakubaszko_kirschnik_pielegniarstwo_1997

    ```{r}
    id_bp <- dane %>%
      filter(BloodPressure == 0)

    dane <- dane %>%
      filter(!Id %in% id_bp$Id)
    ```

4.  `SkinThickness` = 0

    Na podstawie: @malinowski_bozilow_podstawy_1997

    ```{r}
    id_st <- dane %>%
      filter(SkinThickness == 0)

    dane <- dane %>%
      filter(!Id %in% id_st$Id)
    ```

5.  `Insulin` = 846 oraz `Insulin` = 0

    Na podstawie: @gajewski_interna_2022

    ```{r}
    id_i846 <- dane %>%
      filter(Insulin == 846)

    dane <- dane %>%
      filter(!Id %in% id_i846$Id)

    id_i0 <- dane %>%
      filter(Insulin == 0)

    dane <- dane %>%
      filter(!Id %in% id_i0$Id)
    ```

6.  `BMI` = 0

    Na podstawie: @stupnicki_wskaznik_2016

    ```{r}
    id_bmi <- dane %>%
      filter(BMI == 0)

    dane <- dane %>%
      filter(!Id %in% id_bmi$Id)
    ```

Wyżej wymienione przypadki zostają usunięte ze zbioru danych.

## Występowanie obserwacji odstających

```{r}
#| fig-cap: "Wykresy pudełkowe danych"
#| label: fig-box

dane1 <- scale(dane[,-c(1,10)], center = F)

boxplot(dane1[,c(-1,-10)], las = 2)

```

Zmienne zostały poddane standaryzacji, dzięki czemu mogły one zostać przedstawione na jednym wykresie. Z @fig-box można wynioskować, że należy zbadać występowanie obserwacji odstających.

### Wielowymiarowe elementy odstające

```{r}
#| tbl-cap: "Elementy odstające" 
#| label: tbl-outliers

tbl <- dane %>% 
  group_by(Outcome) %>% 
  mahalanobis_distance(-Id) %>%
  as.data.frame() %>% 
  filter(is.outlier == TRUE)

kable(tbl)
```

Korzystając z odległości Mahalanobisa zidentyfikowane zostały nietypowe obserwacje. W tabeli @tbl-outliers przedstawione są wielowymiarowe elementy odstające, które zostają usunięte ze zbioru danych, by nie zaburzać statystyk oraz parametrów.

```{r}
dane <- dane %>% 
  filter(!Id %in% tbl$Id)
```

# Analiza zbioru danych

## Podstawowe statystyki opisowe

```{r}
#| tbl-cap: "Podstawowe statystyki"
#| label: tbl-stat2

kable(summary(dane[, 2:9]))
```

W @tbl-stat2 przedstawione zostały podstawowe statystyki już po usunięciu obserwacji nieprawidłowych oraz odstających. Możemy z niej odczytać między innymi średnie wartości zmiennych ze zbioru. Widać, że zmienne po wstępnym czyszczeniu zbioru średnio przyjmują wartości zgodne z wiedzą medyczną.

Z tabeli można również odczytać, że:

-   Większość pacjentek miała 0, 1 lub 2 ciąże, mediana wynosi 2, a najwięcej przebytych ciąż dla jednej pacjentki to aż 15

-   Mediana zmiennej `Glucose` jest zbliżona do średniej, więc można przypuszczać, że ma rozkład zbliżony do symetrycznego

-   To samo można powiedzieć o wszystkich pozostałych zmiennych

-   Większość pacjentek jest w wieku do 30 lat

## Korelacje

```{r}
#| fig-cap: "Wizualizacja macierzy korelacji"
#| label: fig-cormat

library(ggcorrplot)
library(rstatix)

dane$Pregnancies <- as.numeric(dane$Pregnancies)
dane$Glucose <- as.numeric(dane$Glucose)
dane$BloodPressure <- as.numeric(dane$BloodPressure)
dane$SkinThickness <- as.numeric(dane$SkinThickness)
dane$Insulin <- as.numeric(dane$Insulin)
dane$Age <- as.numeric(dane$Age)
dane$Outcome <- as.numeric(dane$Outcome)
ggcorrplot(cor_mat(subset(dane, select = -c(Id, Outcome))), p.mat=corr_pmat(subset(dane, select = -c(Id, Outcome))), lab=F, colors = c("lightblue", "skyblue", "darkblue"))
```

Patrząc na wykres macierzy korelacji widać, że silnie skorelowane pary zmiennych to: `Pregnancies` i `Age`, `Insulin` i `Glucose`, `SkinThickness` i `BMI`, a zmienna `DiabetesPedigreeFunction` nie koreluje z pozostałymi.

```{r}
#| tbl-cap: "Macierz korelacji"
#| label: tbl-cormat

kable(cor_mat(subset(dane, select = -c(Id, Outcome))))
```

@tbl-cormat potwierdza powyższe związki. Wraz ze wzrostem zmiennej `Age` (wiek) rośnie również `Pregnancies` (ilość przebytych ciąż), tak samo w przypadku, gdzie wartość korelacji jest bliska jeden oraz dodatnia. Pozostałe zmienne nie są silnie skorelowane - nie ma między nimi zależności liniowej.

## Analiza związków między zmiennymi

### Histogramy zmiennych

```{r}
#| fig-cap: "Histogramy zmiennych"
#| label: fig-hist_all

par(mfrow=c(3, 3), mar=c(4, 4, 2, 1), oma=c(0, 0, 2, 0))

for (i in 1:length(subset(dane, select = -c(Id, Outcome)))) {
  hist(subset(dane, select = -c(Id, Outcome))[, i], main=names(subset(dane, select = -c(Id, Outcome)))[i], col="skyblue", xlab="", ylab="", border="black")
}
```

Na podstawie histogramów można podejrzewać, że większa część obserwacji ma małą liczbę ciąż, niski poziom insuliny oraz DiabetesPedigreeFunction i jest młodsza. Grubość skóry i BMI wydają się rozkładać w miarę równomiernie wokół średniej.

### Zmienna `Outcome`

```{r}
#| fig-cap: "Wykres kołowy zmiennej Outcome"
#| label: fig-piechart

out <- plyr::count(dane, 'Outcome')

ggplot(out, aes(x = "", y = freq, fill = factor(Outcome))) +
  geom_bar(width = 1, stat = "identity") +
  geom_text(aes(label = paste0(round(freq/sum(freq) * 100, 1), "%")),
            position = position_stack(vjust = 0.5),
            color = "white") +
  coord_polar(theta = "y") +
  theme_void() +
  scale_fill_manual(values = c("0" = "skyblue", "1" = "darkblue")) +
  labs(fill = "Outcome")
```

```{r}
#| tbl-cap: "Ilość obserwacji w podziale na Outcome"
#| label: tbl-freq

freq <- data.frame(plyr::count(dane, 'Outcome'))
colnames(freq) <- c("Outcome", "Ilość wystąpień")
kable(freq)
```

Dla zmiennej `Outcome` wyniki zostały przedstawione w postaci wykresu kołowego @fig-piechart. W taki sposób widać, że ponad dwa razy więcej w tym zbiorze jest kobiet, które nie mają cukrzycy - jest ich aż 258.

### Wiek w podziale na `Outcome`

```{r}
cukrzycy <- dane[dane$Outcome == 1,]

zdrowi <- dane[dane$Outcome == 0,]
```

```{r}
#| fig-cap: "Rozkład wieku w podziale na zmienną Outcome"
#| label: fig-box_age_outcome

dane %>%  
  ggboxplot(x = "Outcome", y = "Age", combine = 1, color = "Outcome", add = "jitter")+
  scale_color_manual(values = c("darkblue", "skyblue"), labels = c("0", "1"))+
  scale_x_discrete(labels = c("0", "1")) +
  theme_minimal()
```

Z wykresu pudełkowego można odczytać, że cukrzyca występuje u osób zazwyczaj po 30 roku życia. Zaś u osób młodszych (między 20 a 30 rokiem życia) rzadziej diagnozowano cukrzycę.

```{r}
#| tbl-cap: "Średni wiek w podziale na Outcome"
#| label: tbl-age_outcome

age_outcome <- data.frame(mean(cukrzycy$Age), mean(zdrowi$Age))
colnames(age_outcome) <- c("Średni wiek cukrzyka", "Średni wiek osoby zdrowej")
kable(age_outcome)
```

Obliczenia potwierdzają poprzednie przypuszczenia.

### Ciąże w podziale na `Outcome`

```{r}
#| fig-cap: "Wykres pudełkowy zmiennej Pregnancies z podziałem na Outcome"
#| label: fig-preg_outcome

dane %>%  
  ggboxplot(x = "Outcome", y = "Pregnancies", combine = 1, color = "Outcome", add = "jitter")+
  scale_color_manual(values = c("darkblue", "skyblue"), labels = c("0", "1"))+
  scale_x_discrete(labels = c("0", "1")) +
  theme_minimal()
```

Różnica w ilości ciąż w podziale na grupy jest nie aż tak duża jak przy `Age`.

```{r}
#| tbl-cap: "Średnia ilość ciąż w podziale na Outcome"
#| label: tbl-preg_outcome

preg_outcome <- data.frame(mean(cukrzycy$Pregnancies), mean(zdrowi$Pregnancies))
colnames(preg_outcome) <- c("Średnia ilość ciąż cukrzyka", "Średnia ilość ciąż osoby zdrowej")
kable(preg_outcome)
```

Ponownie, to, co można było podejrzewać na podstawie wykresu, obliczenia potwierdziły.

### `Age` i `Pregnancies`

```{r}
#| fig-cap: "Wykres punktowy zależności wieku od ilości ciąż"
#| label: fig-preg_age

dane %>% 
  ggplot(aes(x = Pregnancies, y = Age))+
  geom_point(color = "darkblue")+
  theme_minimal()
```

Korelacja między `Age` i `Pregnancies` wynosi 0.72, co jest największą wartością korelacji między zmiennymi w tym zbiorze danych. Wykres punktowy nie sugeruje wprost zależności liniowej pomiędzy tymi zmiennymi.

Jako rozszerzenie badania korelacji między dwiema zmiennymi stosuje się również model regresji liniowej.

```{r include=FALSE}
age_preg <- lm(Age ~ Pregnancies, dane)
summary(age_preg)
```

Zmienna `Pregnancies` jest istotna statystycznie przy wyjaśnianiu zmienności zmiennej `Age`. Jednak $R^2$ wynosi jedynie $51\%$, czyli za pomocą tego modelu można wyjaśnić jedynie $51\%$ zmienności zmiennej `Age`.

Warto przetestować hipotezę: $H_0$: zależność między `Age` a `Pregnancies` jest liniowa.

```{r}
#| tbl-cap: "Wartości p dla testów na liniowość"

library(lmtest)
rain <- raintest(age_preg)
reset <- resettest(age_preg)
harv <- harvtest(age_preg)
tests <- c(rain$p.value, reset$p.value, harv$p.value)
tests <- matrix(tests, byrow = T, ncol = 3)
colnames(tests) <- c("Test Rainbow", "Test RESET", "Teast Harvey'a-Colliera")
kable(tests)
```

Test *Rainbow* oraz test *Harvey'a-Colliera* na liniową zależność zmiennych nie dały podstaw do odrzucenia hipotezy zerowej $H_0$ o występowaniu liniowości, jednak test *Reset* ją odrzucił. Być może dlatego, że testuje on rozszerzanie modelu o potęgi zmiennych objaśniających, czyli model rozbudowany mógłby być o wiele lepszy niż liniowy i oryginalny model jest niewystarczający.

# Budowa modeli

## Regresja logistyczna

Najpierw następuje podział danych na część treningową oraz testową. Część treningowa będzie stanowiła $85\%$ danych, reszta będzie częścią testową.

```{r}
#| tbl-cap: "Podział danych"
#| label: tbl-split
dane2 <- dane[,-1]
dane2$Outcome <- as.factor(dane2$Outcome)
split <- initial_split(dane2,0.85) #funkcja tworząca podział
test <- testing(split) #tworznie zbioru testowego
trening <- training(split) #tworzenie zbioru treningowego
xd <- nrow(test)
xdd <- nrow(trening)
xddd <- matrix(c(xd, xdd), ncol = 2, byrow = T)
xddd <- data.frame(xddd)
colnames(xddd) <- c("Część testowa", "Część treningowa") 
kable(xddd) 
```

Następnie zdefiniowana zostaje formuła oraz dodany zostaje krok normalizujący dane, by ujednolicić wpływ zmiennych na model. Dodany zostaje model oraz wcześniej przygotowana formuła do przepływu danych.

```{r}
model <- logistic_reg(mode = "classification",
                      engine = "glm")

reg_rec <- recipe(Outcome~., data = trening) %>% 
step_normalize()
```

```{r}
reg_wf <- workflow() %>%
  add_model(model) %>% #dodajemy model
  add_recipe(reg_rec) #dodajemy wcześniej przygotowany przepis
```

Można przejść do uczenia modelu na części treningowej.

```{r include=FALSE}
reg_wf_fit <- reg_wf %>%
  fit(data = trening)
reg_wf_fit
```

```{r}
#| tbl-cap: "Zestawienie predykcji i wartości rzeczywistej"
#| label: tbl-pred_real

reg_pred <- predict(reg_wf_fit,test) #ramka danych z predykcją 
reg_df1 <- bind_cols(reg_pred, 'target' = test$Outcome)
colnames(reg_df1) <- c("Predykcja modelu", "Wartość rzeczywista")
kable(head(reg_df1))
```

@tbl-pred_real przedstawia zestawienie predykcji dokonanej przez model regresji logistycznej oraz wartości rzeczywistej ze zbioru danych.

```{r}
#| fig-cap: "Wizualizacja skuteczności przeprowadzonej klasyfikacji"
#| label: fig-logreg


conf_reg <- conf_mat(reg_df1, truth = "Wartość rzeczywista", estimate = "Predykcja modelu")
autoplot(conf_reg, type = "heatmap")
```

Na @fig-logreg przedstawiona została macierz pomyłek. Można z niej odczytać, ile wartości zostało przewidzianych poprawnie, a ile źle.

Dokładność (accuracy) modelu:

$$
Accuracy = \frac{TP + TN}{TP + TN + FP + TN}
$$

gdzie TP oznacza True Positive, TN - True Negative, FP - False Positive, FN - False Negative.

```{r include=FALSE}
acc <- (31+15)/ (1+15+31+10)
```

Około $81\%$ przypadków zostało zakwalifikowane poprawnie.

```{r}
plogreg <- as.numeric(reg_pred$.pred_class) 
xdd <- as.numeric(test$Outcome)
rmselog<- rmse(xdd, plogreg)
tbllog <- data.frame(c(format(round(rmselog, 2), nsmall = 2),
                       format(round(acc, 2), nsmall = 2)),
                     row.names = c("RMSE", "Accuracy"))
colnames(tbllog) <- c("Wartość")
kable(tbllog)
```

## LDA

Model analizy dyskryminacyjnej

```{r}
dane3 <- trening %>% 
  mutate_if(is.numeric, scale) %>% 
  as.data.frame()
```

```{r}
#| tbl-cap: "Średnie zmiennych w podziale na grupy"
#| label: tbl-means_lda

lda <- lda(Outcome~., data = dane3)
kable(data.frame(lda$means))
```

Prawdopodobieństwa występowania poszczególnych stanów zmiennej zależnej `Outcome`. 0 (brak cukrzycy) występowało w $68\%$ przypadków, a 1 (cukrzyca) w $32\%$.

Im większa różnica w średnich grupowych, tym ta zmienna niezależna lepiej dyskryminuje, w tym przypadku najlepiej dyskryminuje zmienna `Glucose` .

Na podstawie współczynników wagowych w kombinacji liniowej również można stwierdzić, który współczynnik najlepiej dyskryminuje, w tym przypadku jest to również zmienna `Glucose`.

Na podstawie wzoru na liczbę zmiennych testowych dyskryminacyjnych:

$$
min(m, k - 1)
$$

gdzie $m$ - liczba zmiennych niezależnych, $k$ - liczba poziomów zmiennej zależnej. W tym zbiorze danych jest 8 zmiennych niezależnych oraz dwa poziomy zmiennej zależnej. Oznacza to, że jest jedna zmienna dyskryminacyjna na podstawie wzoru.

```{r}
#| fig-cap: "LDA wykres diagnostyczny"
#| label: fig-lda

test_lda <- test %>% 
  mutate_if(is.numeric, scale) %>% 
  as.data.frame()
pred_tr <- predict(lda, newdata = test_lda)
plot(lda)
```

Z wykresu @fig-lda można wywnioskować, że 0 występowało dla mniejszych wartości a 1 dla większych, co zgadza się z przypuszczeniami, że dla mniejszych wartości `Glucose` większość pacjentów nie ma cukrzycy.

```{r}
#| fig-cap: "Wizualizacja skuteczności przeprowadzonej klasyfikacji"
#| label: fig-lda_confmat

pred <- predict(lda, newdata = test_lda)
tab <- table(obs = test_lda$Outcome, pred = pred$class)
conf<- conf_mat(tab, truth = "target", estimate = ".pred_class")
autoplot(conf, type = "heatmap")
```

@fig-lda_confmat przedstawia macierz pomyłek, czyli ile obserwacji zostało zaklasyfikowanych poprawnie, a ile niepoprawnie.

```{r}
tab_tr <- bind_cols(obs_class = test_lda$Outcome,
                    pred_class = pred_tr$class) |>  
table()

acc_tr <- sum(diag(tab_tr))/sum(tab_tr)
```

```{r}
plda <- as.numeric(pred$x) 
xdd <- as.numeric(test$Outcome)
rmselda<- rmse(xdd, plda)
tbllda <- data.frame(c(format(round(rmselda, 2), nsmall = 2),
                       format(round(acc_tr, 2), nsmall = 2)),
                     row.names = c("RMSE", "Accuracy"))
colnames(tbllda) <- c("Wartość")
```

```{r}
#| tbl-cap: "Wartości RMSE i Accuracy dla LDA"
#| label: tbl-lda

kable(tbllda)
```

## Drzewo decyzyjne

Implementacja modelu drzewa.

```{r}
#| fig-cap: "Wizualizacja modelu drzewa decyzyjnego"
#| label: fig-tree

drzewo <- rpart(Outcome ~ . , data = trening)
rpart.plot(drzewo)
```

Należy zacząć "od góry", stwierdzając czy jak w tym przypadku pacjent posiada glukozę równą 128, jeśli tak, to należy iść w lewo, jeśli jest inaczej to w prawo. Robimy tak aż do momenu dojścia do liścia tzn. najniższej warstwy drzewa. Procent w prostokątach oznacza jaki procent osób ma taki przypadek.

```{r}
#| fig-cap: "Ważność zmiennych"
#| label: fig-importance

var_importance <- vip(drzewo, num_features = 8)
print(var_importance)
```

Na podstawie wykresu @fig-importance można stwierdzić, że zmienna `Glucose` była najważniejsza dla zbioru, dlatego jest głównym wierzchołkiem.

```{r}
#| tbl-cap: "Macierz pomyłek dla części treningowej"
#| label: tbl-tree-mac-trening

pp <- predict(drzewo, trening, type = 'class')
conf_matrix_tree_train <- confusionMatrix(pp, trening$Outcome, positive = '1')
kable(conf_matrix_tree_train$table)
```

Dokładność części treningowej wynosi $89,3\%$ .

```{r}
#| tbl-cap: "Macierz pomyłek dla części testowej"
#| label: tbl-tree-mac-test

p <- predict(drzewo, test, type = 'class')
conf_matrix_tree_test <- confusionMatrix(p, test$Outcome, positive = '1')
kable(conf_matrix_tree_test$table)
```

Poprawnie zostało zaklasyfikowanych 48 z 57 obserwacji z części testowej.

```{r}
#| tbl-cap: Wartości RMSE i Accuracy dla drzewa decyzyjnego
#| label: tbl-tree


p1 <- as.numeric(p) 
xdd <- as.numeric(test$Outcome)
rmse_tree<- rmse(xdd, p1)
tbltree <- data.frame(c(format(round(rmse_tree, 2), nsmall = 2),
            format(round(conf_matrix_tree_test$overall[1], 2), nsmall = 2)),
            row.names = c("RMSE", "Accuracy"))
colnames(tbltree) <- c("Wartość")
kable(tbltree)
```

## Las losowy

Budowa modelu lasu losowego.

```{r}
rf <- randomForest(Outcome ~ . , data = trening)
```

Błąd wynosi około $22\%$, więc dokładność części treningowej wynosi około $78\%$.

```{r}
#| tbl-cap: Macierz pomyłek dla części treningowej
#| label: tbl-rf

rf_pred <- predict(rf, trening)
conf_matrix_forest_train <- confusionMatrix(rf_pred, trening$Outcome)
kable(conf_matrix_forest_train$table)
```

Część treningowa ma $100\%$ dokładności.

```{r}
#| tbl-cap: Macierz pomyłek dla części testowej
#| label: tbl-rf-mac

rf_pred2 <- predict(rf, test)
conf_matrix_forest_test <- confusionMatrix(rf_pred2, test$Outcome)
kable(conf_matrix_forest_test$table)
```

Część testowa ma około $81\%$ dokładności.

Gdy dokładność modelu na części treningowej wynosi $100\%$, to można przypuszczać, że model został przeuczony i powinno się zastosować na przykład dostosowanie paramterów modelu lasu losowego. Jednak dokładność części testowa wynosi około $81\%$, więc model dobrze dostosowuje się do nowych, nieznanych danych. Można zakładać, że do przeuczenia modelu nie doszło.

```{r}
#| fig-cap: "Wykres błędów w zależności od liczby drzew w lesie losowym"
#| label: fig-rferror

plot(rf, main = "")
```

Na wykresie @fig-rferror widać, jak zmienia się błąd wraz z liczbą drzew decyzyjnych w lesie losowym. Można stwierdzić, że błąd wraz z ilością drzew się stabilizuje, lecz nie maleje.

```{r}
#| fig-cap: "Istotność zmiennych w lesie losowym"
#| label: fig-ist-rf

varImpPlot(rf, sort = T, main = "")
```

Podobnie jak w drzewie decyzyjnym, zmienna `Glucose` ma największe znaczenie.

```{r}
#| tbl-cap: "Wartości RMSE i Accuracy dla lasu losowego"
#| label: tbl-rf-rmse-acc


p_las <- as.numeric(rf_pred2) 
xdd <- as.numeric(test$Outcome)
rmselas<- rmse(xdd, p_las)
tbllas <- data.frame(c(format(round(rmselas, 2), nsmall = 2),
               format(round(conf_matrix_forest_test$overall[1], 2), nsmall = 2)),  row.names = c("RMSE", "Accuracy"))
colnames(tbllas) <- c("Wartość")
kable(tbllas)
```

# Porównanie modeli

```{r}
#| tbl-cap: "Miary RMSE i Accuracy"
#| label: tbl-rmse_r2

rmse_r2 <- cbind(tbllog, tbllda, tbltree, tbllas)
rownames(rmse_r2) <- c("RMSE", "Accuracy")
colnames(rmse_r2) <- c("Regresja logistyczna", "LDA", "Drzewo decyzyjne", "Las losowy")
kable(rmse_r2)
```

RMSE, czyli błąd średniokwadratowy mierzy średnią różnicę między przewidzianymi a prawdziwymi wartościami. Najmniejszą wartość ma dla modelu regresji logistycznej, czyli w tym modelu są najmniejsze błędy predykcji.

Z tabeli @tbl-rmse_r2 wynika, że model regresji logistycznej będzie najlepszy, najwyższa dokładność i najmniejszy błąd średniokwadratowy.

# Źródła

<https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset>
